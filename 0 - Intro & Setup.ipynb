{
 "metadata": {
  "name": "",
  "signature": "sha256:0ad54fe65df2b81fe38b822f6608971a29ee6bd225ff95abf4ea0e05f46b7678"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Topic Modeling for Fun and Profit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook, you'll\n",
      "\n",
      "* check you have all dependencies installed correctly\n",
      "* check you have downloaded all necessary data\n",
      "* get up to speed with efficient Python data access patterns"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tutorial setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check all dependencies are installed correctly (see the [README](https://github.com/piskvorky/topic_modeling_tutorial/)) (highlight each cell with your mouse and press `SHIFT`+`ENTER`):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gensim\n",
      "gensim.utils.lemmatize(\"The quick brown fox jumps over the lazy dog!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download('brown')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import textblob\n",
      "textblob.TextBlob(\"The quick brown fox jumps over the lazy dog!\").noun_phrases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the above executes without errors, you'll see a number appear to the left of each of these cell prompts, and you're good to go!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In case you're using [virtual evironments](http://docs.python-guide.org/en/latest/dev/virtualenvs/) (recommended), check that the right package/location was picked up by Python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(scipy.__version__, scipy.__file__)\n",
      "print(gensim.__version__, gensim.__file__)\n",
      "scipy.show_config()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Check training data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure you have downloaded all necessary data files (again, see the [README](https://github.com/piskvorky/topic_modeling_tutorial/)):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lh ./data/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should see at least two entries there: `simplewiki-20140623-pages-articles.xml.bz2` and `20news-bydate.tar.gz`."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Quick Python recap"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Data streaming, generators, iterators"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generators are a built-in way to iterate over a sequence **once**, without materializing all its elements at the same time:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def odd_numbers():\n",
      "    \"\"\"\n",
      "    Yield one odd number after another.\n",
      "    \n",
      "    Don't try to materialize its result in plain list, with `list(odd_numbers)`,\n",
      "    because the sequence is infinite and you'll run out of RAM!\n",
      "    \"\"\"\n",
      "    result = 1\n",
      "    while True:\n",
      "        yield result  # `yield` instead of `return`!\n",
      "        result += 2\n",
      "\n",
      "odd_numbers_generator = odd_numbers()\n",
      "\n",
      "for odd_number in odd_numbers_generator:\n",
      "    print(odd_number)\n",
      "    if odd_number > 10:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll be using this pattern of \"generate a data point, process it, forget it\" often, because it allows us to bypass RAM limitations. With generators we can process huge text corpora in constant memory, using clever algorithms that don't mind operating one-data-point-at-a-time.\n",
      "\n",
      "This is in contrast to plain Python lists, Pandas frames or even NumPy and SciPy arrays, where the entire sequence must be known beforehand and mapped into (virtual) memory fully.\n",
      "\n",
      "Generators and iterators come at a cost: since we're only allowed to go one item after another, it's not possible to skip to the middle of the sequence. Unless we take care of it manually, there's no equivalent of randomly accessing an arbitrary element ala `list`s: `some_list[100]` will work, but `some_generator[100]` won't."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An iterable is like a generator (memory efficient), except it can be iterated over **multiple times**. To achieve that, we override the object's special `__iter__` method (which Python calls every time we loop over the object) to return a generator:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class OddNumbers(object):\n",
      "    def __iter__(self):\n",
      "        result = 1\n",
      "        while True:\n",
      "            yield result\n",
      "            result += 2\n",
      "\n",
      "odd_numbers_iterator = OddNumbers()\n",
      "\n",
      "for odd_number in odd_numbers_iterator:\n",
      "    print(odd_number)\n",
      "    if odd_number > 10:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's all we need to know for our purposes. For more info, read [Data streaming in Python: generators, iterators, iterables](http://radimrehurek.com/2014/03/data-streaming-in-python-generators-iterators-iterables/), or [Python's documentation for \"iterator types\"](https://docs.python.org/2/library/stdtypes.html#iterator-types)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "NumPy & SciPy arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NumPy is a 3rd party package (not built-in). **NumPy arrays are a concise and efficient way to represent a fixed-length list of numbers** (or, actually and uninterestingly for this tutorial, of any objects). Their power comes from pithy array slicing, even in multiple dimensions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a 2D table of random numbers, with 10 rows and 5 columns\n",
      "x = numpy.random.rand(10, 5)\n",
      "\n",
      "print(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print element in 3rd row and 2nd column\n",
      "print(x[2, 1])  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the entire 3rd row\n",
      "print(x[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the entire 2nd column\n",
      "print(x[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print a sub-table (rectangular region), starting at [0, 0] and ending at [4, 2] (exclusive)\n",
      "print(x[:4, :2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and the fact that the underlying implementation is written to be fast (in C, even plugging into fast BLAS where available)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, the **3rd part SciPy package contains `scipy.sparse` arrays**, which are a way to represent vectors and matrices with assumed (implicit) zeros.\n",
      "\n",
      "`scipy.sparse` arrays are not as efficient as NumPy arrays, because they don't plug into BLAS and because their memory access patterns are more involved (cache misses). But not materializing the zeros explicitly can make a huge difference for very sparse arrays (lots of zeros). However, all non-zero values must still reside in memory, so ultimately, for large data, we still resort to generators and data streaming.\n",
      "\n",
      "A common pattern that we'll be using is **combining the efficiency of in-memory arrays** (numpy, scipy.sparse) with the **scalability of data streaming**. Instead of processing one document at a time (slow), or all documents at once (non-scalable), we'll be reading **a chunk of documents** into RAM (= as many documents as RAM allows), processing this chunk, then throwing it away and streaming a new chunk into RAM."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Itertools"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A [built-in Python library](https://docs.python.org/2/library/itertools.html) for efficient work data streams (iterables, iterators, generators):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "infinite_stream = OddNumbers()\n",
      "\n",
      "# compute the first 10 items (and no more) & print them\n",
      "print(list(itertools.islice(infinite_stream, 10)))\n",
      "\n",
      "# lazily concatenate streams; the result is also infinite\n",
      "concat_stream = itertools.chain('abcde', infinite_stream)\n",
      "print(list(itertools.islice(concat_stream, 10)))\n",
      "\n",
      "numbered_stream = enumerate(infinite_stream)  # also infinite\n",
      "print(list(itertools.islice(numbered_stream, 10)))\n",
      "\n",
      "# etc; see the itertools docs for more examples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The examples above show another useful pattern: take a small sample of the stream (e.g. the first ten elements) and convert them into plain Python list, with `list(islice(stream, 10))`. To convert an entire stream into list, simply `list(stream)` (watch out for RAM here though, especially with infinite streams!). Nothing beats the simplicity of `list(stream)` for debugging purposes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Notebooks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At any point, you can save the notebook (any notebook) to disk by pressing `CTRL`+`s` (or `CMD`+`s`). This will **save all changes you've made to the notebook**, including cell outputs, locally to your disk.\n",
      "\n",
      "To discard your notebook changes, simply checkout the notebook file again from git (or extract it again from the repository ZIP archive). This will reset the notebook to its original state, **losing all your changes**."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
